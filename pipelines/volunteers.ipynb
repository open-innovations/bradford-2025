{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volunteering Data\n",
    "\n",
    "Data extracted from Rosterfy and processes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import petl as etl\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path('../')\n",
    "DATA = ROOT / 'data/volunteers'\n",
    "_TARGET = ROOT / 'src/volunteers/_data'\n",
    "SHIFTS = _TARGET / 'shifts'\n",
    "SHIFTS.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = etl.fromcsv(\n",
    "    DATA / 'shifts-raw.csv'\n",
    ").convert(\n",
    "    ('demand', 'attended'), int\n",
    ").convert(\n",
    "    ('hours'), float\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some summary functions with a combination of PETL and Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def summarise(table: etl.Table, column, freq) -> etl.Table:\n",
    "    return (\n",
    "        event_shifts\n",
    "        .cut('date', 'type', column)\n",
    "        .recast(variablefield='type', valuefield=column, reducers=sum)\n",
    "        .replaceall(None, 0)\n",
    "        .todataframe()\n",
    "        .pipe(resample, freq)\n",
    "        .pipe(etl.fromdataframe)\n",
    "        .convert('date', datetime.date)\n",
    "        .sort('date')\n",
    "    )    \n",
    "\n",
    "def resample(df: pd.DataFrame, freq, date_field='date') -> pd.DataFrame:\n",
    "    df[date_field] = df[date_field].pipe(pd.DatetimeIndex)\n",
    "    df.set_index(date_field, inplace=True)\n",
    "    return df.resample(freq).sum().reset_index()\n",
    "\n",
    "def make_cumulative(df: pd.DataFrame):\n",
    "    return (\n",
    "        df.set_index('date').cumsum().reset_index()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_shifts = data.replaceall(\n",
    "    None, 0\n",
    ").aggregate(\n",
    "    key=['date', 'type'],\n",
    "    aggregation={\n",
    "        'attended': ('attended', sum),\n",
    "        'hours': ('hours', sum)\n",
    "    }\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarise(event_shifts, 'attended', 'W-FRI').rename('date', 'week_ending').tocsv(SHIFTS / 'attended_by_week.csv')\n",
    "summarise(event_shifts, 'hours', 'W-FRI').rename('date', 'week_ending').tocsv(SHIFTS / 'hours_by_week.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarise(\n",
    "    event_shifts, 'attended', 'MS'\n",
    ").todataframe().pipe(\n",
    "    make_cumulative\n",
    ").pipe(\n",
    "    etl.fromdataframe\n",
    ").rename(\n",
    "    'date', 'month'\n",
    ").tocsv(SHIFTS / 'attended_cumulative_by_month.csv')\n",
    "\n",
    "summarise(\n",
    "    event_shifts, 'hours', 'MS'\n",
    ").todataframe().pipe(\n",
    "    make_cumulative\n",
    ").pipe(\n",
    "    etl.fromdataframe\n",
    ").rename(\n",
    "    'date', 'month'\n",
    ").tocsv(SHIFTS / 'hours_cumulative_by_month.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert timestamp columns to datetime to work with OI Lume Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoints_monthly['Month ending'] = pd.to_datetime(checkpoints_monthly['Month ending']).dt.strftime('%Y-%m-%d')\n",
    "# shifts_monthly['Month ending'] = pd.to_datetime(shifts_monthly['month ending']).dt.strftime('%Y-%m-%d')\n",
    "# shifts_weekly['Month ending'] = pd.to_datetime(shifts_weekly['week ending']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# checkpoints_monthly.to_csv(os.path.join(OUT_DIR, 'checkpoints_monthly.csv'), index=False)\n",
    "# shifts_monthly.to_csv(os.path.join(OUT_DIR, 'shifts_monthly.csv'), index=False)\n",
    "# shifts_weekly.to_csv(os.path.join(OUT_DIR, 'shifts_weekly.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bd25",
   "language": "python",
   "name": "bd25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
