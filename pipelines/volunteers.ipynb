{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volunteering Data\n",
    "\n",
    "Data extracted from Rosterfy and processes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "from pathlib import Path\n",
    "\n",
    "import petl as etl\n",
    "\n",
    "from utils import make_time_series, make_cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "induction_launch = date.fromisoformat('2024-09-12')\n",
    "first_event = date.fromisoformat('2024-08-16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up references to paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path('../')\n",
    "DATA = ROOT / 'data/published/volunteers'\n",
    "_TARGET = ROOT / 'src/themes/volunteers/_data'\n",
    "PEOPLE = _TARGET / 'people'\n",
    "PEOPLE.mkdir(exist_ok=True, parents=True)\n",
    "SHIFTS = _TARGET / 'shifts'\n",
    "SHIFTS.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read checkpoints data from CSV process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = etl.fromcsv(\n",
    "    DATA / 'checkpoints.csv'\n",
    ").convert(\n",
    "    'date', etl.dateparser('%Y-%m-%d')\n",
    ").convert('count', int).sort(\n",
    "    key=('date', 'checkpoint')\n",
    ").recast(\n",
    "    variablefield='checkpoint', valuefield='count'\n",
    ").replaceall(\n",
    "    None, 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create summarise function. This takes a Pandas dataframe, resamples based on the desired frequency `freq`, adds cumulative counts of each column, converts to a PETL table and renames the date column based on the `title` provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise(df, freq, title):\n",
    "    return (\n",
    "        df\n",
    "            .pipe(make_time_series)\n",
    "            .resample(freq)\n",
    "            .sum()\n",
    "            .pipe(make_cumulative)\n",
    "            .reset_index()\n",
    "            .pipe(etl.fromdataframe)\n",
    "            .convert('date', datetime.date)\n",
    "            .rename({ 'date': title })\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a weekly summary of checkpoints passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints.todataframe(\n",
    ").pipe(\n",
    "    summarise, 'W-SUN', 'Week ending (Sunday)'\n",
    ").selectge('Week ending (Sunday)', induction_launch).tocsv(PEOPLE / 'checkpoints_weekly.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = etl.fromcsv(DATA / 'geo-summary.csv')\n",
    "for geography, table in geo.facet('type').items():\n",
    "    table.tocsv(PEOPLE / f'by_geo_{geography}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = etl.fromcsv(DATA / 'demographics.csv').selectin('category', [\n",
    "    'age_range',\n",
    "])\n",
    "\n",
    "for category, table in demo.facet('category').items():\n",
    "    table.tocsv(PEOPLE / f'by_demographic_{category}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts = etl.fromcsv(\n",
    "    DATA / 'shifts.csv'\n",
    ").convert(\n",
    "    ('demand', 'attended'), int\n",
    ").convert(\n",
    "    ('hours'), float\n",
    ").replaceall(\n",
    "    None, 0\n",
    ").aggregate(\n",
    "    key=['date', 'type'],\n",
    "    aggregation={\n",
    "        'attended': ('attended', sum),\n",
    "        'hours': ('hours', sum)\n",
    "    }\n",
    ").convert(\n",
    "    'date', date.fromisoformat\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some summary functions with a combination of PETL and Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise(table: etl.Table, column, freq) -> etl.Table:\n",
    "    return (\n",
    "        table\n",
    "        .cut('date', 'type', column)\n",
    "        .recast(variablefield='type', valuefield=column, reducers=sum)\n",
    "        .replaceall(None, 0)\n",
    "        .todataframe()\n",
    "        .pipe(make_time_series)\n",
    "        .resample(freq)\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .pipe(etl.fromdataframe)\n",
    "        .convert('date', datetime.date)\n",
    "        .sort('date')\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarise(\n",
    "    shifts, 'attended', 'W-SUN'\n",
    ").selectge(\n",
    "    'date', first_event\n",
    ").rename(\n",
    "    'date', 'week_ending'\n",
    ").tocsv(SHIFTS / 'attended_by_week.csv')\n",
    "\n",
    "summarise(\n",
    "    shifts, 'hours', 'W-SUN'\n",
    ").selectge(\n",
    "    'date', first_event\n",
    ").rename(\n",
    "    'date', 'week_ending'\n",
    ").tocsv(SHIFTS / 'hours_by_week.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarise(\n",
    "    shifts, 'attended', 'W-SUN'\n",
    ").todataframe(\n",
    ").set_index('date').cumsum().reset_index(\n",
    ").pipe(\n",
    "    etl.fromdataframe\n",
    ").selectge(\n",
    "    'date', first_event\n",
    ").rename(\n",
    "    'date', 'week_ending'\n",
    ").tocsv(SHIFTS / 'attended_cumulative_by_week.csv')\n",
    "\n",
    "summarise(\n",
    "    shifts, 'hours', 'W-SUN'\n",
    ").todataframe(\n",
    ").set_index('date').cumsum().reset_index(\n",
    ").pipe(\n",
    "    etl.fromdataframe\n",
    ").selectge(\n",
    "    'date', first_event\n",
    ").rename(\n",
    "    'date', 'week_ending'\n",
    ").tocsv(SHIFTS / 'hours_cumulative_by_week.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert timestamp columns to datetime to work with OI Lume Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoints_monthly['Month ending'] = pd.to_datetime(checkpoints_monthly['Month ending']).dt.strftime('%Y-%m-%d')\n",
    "# shifts_monthly['Month ending'] = pd.to_datetime(shifts_monthly['month ending']).dt.strftime('%Y-%m-%d')\n",
    "# shifts_weekly['Month ending'] = pd.to_datetime(shifts_weekly['week ending']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# checkpoints_monthly.to_csv(os.path.join(OUT_DIR, 'checkpoints_monthly.csv'), index=False)\n",
    "# shifts_monthly.to_csv(os.path.join(OUT_DIR, 'shifts_monthly.csv'), index=False)\n",
    "# shifts_weekly.to_csv(os.path.join(OUT_DIR, 'shifts_weekly.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bd25-L4uOQWuf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
